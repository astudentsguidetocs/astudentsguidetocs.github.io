# Society

Designing for society and thinking about morality is important in any profession;
especially engineering. If you went to Mines, classes like Nature & Human Values (NHV),
however much hated they are by the public, should prep you for these sort of questions.
But I urge you to always be thinking about the ethics.

I know a lot of people who work for defense contractors and I really like and respect
them as people. I also know people who have left those scenarios, and I respect them too.
It's important, especially in those situations, to be thinking about the full picture.
Are you making a product that's going to kill people and be used for mass destruction?
Some of my friends view it as *defense* for the security of our country. Some left
because they felt it was *offense*. I see both perspectives. The point I want to
make here is that you should be thinking about it and making your own decisions.

If you make some sort of AI or algorithm, what implications does it have on
people's jobs and livelihoods? Do you see the full picture of what you're designing,
or are you mindlessly working on a tiny part of the system? 

[Catalyst](https://www.amazon.com/Catalyst-Star-Wars-Rogue-Novel/dp/1101967005), a novel relating
to [Star Wars: Rogue One](https://en.wikipedia.org/wiki/Rogue_One) is actually a pretty good
example of this. The writer, James Luceno, accurately portrays how scientists and engineers on the [Death Star](https://en.wikipedia.org/wiki/Death_Star) 
project weren't aware of the bigger picture of what they were making. They just thought
it was an important, tiny piece of science. But it was actually being used to make a weapon
that could remove entire planets and commit genocide on insanely large amounts of people.
Although this is fiction, there's some realism in this. It's analogous to [The Nazi engineers: reflections on technological ethics in hell](https://pubmed.ncbi.nlm.nih.gov/20844979/) 
by Eric Katz, which was taught in NHV, and spoke about how those engineers probably *did* 
know what they were doing and still did it anyways.

[The Social Dilemma](https://thesocialdilemma.com) is another great documentary involving
engineering ethics, where former executives of big social media companies talk about their 
invention. They mention that **you and your attention are the products being sold**. The 
way these companies make money is by selling your data to other companies and selling products 
to you tailored to your exact interests (because they're tracking your exact interests). 

While this is an unfortunate reality of the business model of the internet today,
you should consider the effect that this has on people. Are you writing software
that is going to learn people's preferences and then sell that data? Is this software
going to cause addiction and more societal problems than the good it does? All
questions to be asking.

Just like in the accessibility section, you should want to design for society
without any external motivators, but it's the law now with things like the [General Data Protection Regulation (GDPR)](https://gdpr.eu/what-is-gdpr/). Even if you don't live in the EU, chances are you'll have customers in the EU,
and be legally bound to laws regarding their data. Even so, many states in the US as well as many countries are
beginning to write laws like this.

**Be aware**. Don't be ignorant to the effects your design and your engineering has on the world.
